{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456af242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:/Users/laure/OneDrive/Documents/ERDC_FRF/pyCMTB\")\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3680f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'objMapPrep'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2ef1463dedcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mDT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobjMapPrep\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoarseBackground\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinMorph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgetdatatestbed\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetDataFRF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtestbedutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msblib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'objMapPrep'"
     ]
    }
   ],
   "source": [
    "# FRFbathy_interp\n",
    "\"\"\"\n",
    "This script is based on an original Matlab script by Bonnie Ludka\n",
    "Rewritten in python by Dylan Anderson on 7/25/2019\n",
    "\n",
    "It is written for LARC bathy interpolation and produces a number of plots at each step to check the processing\n",
    "\"\"\"\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import datetime as DT\n",
    "from objMapPrep import coarseBackground, binMorph\n",
    "from getdatatestbed import getDataFRF\n",
    "from testbedutils import sblib as sb\n",
    "import objMapPlots\n",
    "from objMapInterp import map_interp\n",
    "from makeNetCDF import py2netCDF as p2nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da34884",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.1        # meters elevation\n",
    "Lx = 20             # meters cross-shore\n",
    "Ly = 150            # meters alongshore\n",
    "countBinThresh = 3  # number of data points required in bin\n",
    "nmseThresh = 0.7    # threshold for including data into the final product based on nmse Estimate\n",
    "# backgroundGridLoc = 'http://134.164.129.55/thredds/dodsC/cmtb/grids/TimeMeanBackgroundDEM/backgroundDEMt0_TimeMean.nc'\n",
    "putFilesHere = \"figures/objMapQAQC\"\n",
    "outFpath = \"outNetCDFfiles\"\n",
    "###########\n",
    "# set start, end\n",
    "start, end = DT.datetime(2010, 3, 17), DT.datetime(2020, 2, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bf5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets reduce to a new coarser grid that will have multiple observations in each bin\n",
    "cdx = Lx/2  # 100 # crossshore res ~8m (?)\n",
    "cdy = Ly/2  # 10  # alongshore res ~50m (?)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19bf4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestBackground(ncfileLoc, date, **kwargs):\n",
    "    backgroundFname = kwargs.get('background',\n",
    "                             \"http://134.164.129.55/thredds/dodsC/cmtb/grids/TimeMeanBackgroundDEM/backgroundDEMt0_TimeMean.nc\")\n",
    "\n",
    "    globList = sorted(glob.glob(os.path.join(ncfileLoc, '*.nc')))\n",
    "    listDateDiffs =np.array([DT.datetime.strptime(f.split('_')[-1], '%Y%m%d.nc') for f in globList]) - date\n",
    "    yesterdayFile = globList[np.argmax(listDateDiffs[listDateDiffs<DT.timedelta(0)]).squeeze()]\n",
    "    if os.path.isfile(yesterdayFile):\n",
    "        # load yesterdays file for background\n",
    "        print('    background: {}'.format(yesterdayFile))\n",
    "        ncfile = nc.Dataset(yesterdayFile)\n",
    "        xFRFbackground = ncfile['xFRF'][:]\n",
    "        yFRFbackground = ncfile['yFRF'][:]\n",
    "        zbg = ncfile['elevation'][:].squeeze()\n",
    "    else:\n",
    "        background = nc.Dataset(backgroundFname)\n",
    "        xFRFbackground = background['xFRF'][:]\n",
    "        yFRFbackground = background['yFRF'][:]\n",
    "        zbg = background['elevation'][:]\n",
    "    \n",
    "    return xFRFbackground, yFRFbackground, zbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildCollectiveXYZ(bathy, dune, pier, claris):\n",
    "    zs, ys, xs, types = [], [], [], []\n",
    "    if bathyAll is not None and bathy is not None:\n",
    "        # this is not a grid so does not need to be mesh gridded like others\n",
    "        zs = np.ma.concatenate([zs, bathy['elevation'].flatten()])\n",
    "        ys = np.ma.concatenate([ys, bathy['yFRF'].flatten()])\n",
    "        xs = np.ma.concatenate([xs, bathy['xFRF'].flatten()])\n",
    "        types.append(' bathy')\n",
    "    if duneAll is not None and dune is not None:\n",
    "        xx, yy = np.meshgrid(dune['xFRF'], dune['yFRF'])\n",
    "        # repeat in time xxFRFbackground and yyFRFbackground grid\n",
    "        allXs = np.tile(xx, [np.size(dune['time']), 1 , 1])\n",
    "        allYs = np.tile(yy, [np.size(dune['time']), 1 , 1])\n",
    "        # now eliminate xxFRFbackground/yyFRFbackground values that the dune['elevation'] values are masked (True)\n",
    "        xs = np.ma.concatenate([xs, allXs[~dune['elevation'].mask].flatten()])\n",
    "        ys = np.ma.concatenate([ys, allYs[~dune['elevation'].mask].flatten()])\n",
    "        zs = np.ma.concatenate([zs, dune['elevation'][~dune['elevation'].mask].flatten()])\n",
    "        types.append(' dune')\n",
    "    if pierAll is not None and pier is not None:\n",
    "        xx, yy = np.meshgrid(pier['xFRF'], pier['yFRF'])\n",
    "        # repeat in time xxFRFbackground and yyFRFbackground grid\n",
    "        allXs = np.tile(xx, [np.size(pier['time']), 1 , 1])\n",
    "        allYs = np.tile(yy, [np.size(pier['time']), 1 , 1])\n",
    "        # now eliminate xxFRFbackground/yyFRFbackground values that the dune['elevation'] values are masked (True)\n",
    "        xs = np.ma.concatenate([xs, allXs[~pier['elevation'].mask].flatten()])\n",
    "        ys = np.ma.concatenate([ys, allYs[~pier['elevation'].mask].flatten()])\n",
    "        zs = np.ma.concatenate([zs, pier['elevation'][~pier['elevation'].mask].flatten()])\n",
    "        types.append(' pier')\n",
    "    if clarisAll is not None and claris is not None:\n",
    "        xx, yy = np.meshgrid(claris['xFRF'], claris['yFRF'])\n",
    "        # repeat in time xxFRFbackground and yyFRFbackground grid\n",
    "        allXs = np.tile(xx, [np.size(claris['time']), 1 , 1])\n",
    "        allYs = np.tile(yy, [np.size(claris['time']), 1 , 1])\n",
    "        # now eliminate xxFRFbackground/yyFRFbackground values that the dune['elevation'] values are masked (True)\n",
    "        xs = np.ma.concatenate([xs, allXs[~claris['elevation'].mask].flatten()])\n",
    "        ys = np.ma.concatenate([ys, allYs[~claris['elevation'].mask].flatten()])\n",
    "        zs = np.ma.concatenate([zs, claris['elevation'][~claris['elevation'].mask].flatten()])\n",
    "        types.append(' claris')\n",
    "    \n",
    "    return xs, ys, zs, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900cf3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DT.timedelta(days=1)\n",
    "\n",
    "go = getDataFRF.getObs(start, end)\n",
    "bathyAll = go.getBathyTransectFromNC(forceReturnAll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt, date in enumerate(sb.createDateList(start, end, dt)):   # make one merged product (hourly)\n",
    "    print('--- making grid for {}'.format(date))\n",
    "    ###################\n",
    "    # now gather data #\n",
    "    ###################\n",
    "    # Gather Data for today's interpolations\n",
    "    go = getDataFRF.getObs(date, date+dt)\n",
    "    # now gather data\n",
    "    pierAll = go.getLidarDEM(lidarLoc='pier')\n",
    "    duneAll = go.getLidarDEM(lidarLoc='dune')\n",
    "    clarisAll = None # go.getLidarDEM(lidarLoc='claris')\n",
    "    \n",
    "    # 1. Pick appropriate background file\n",
    "    xFRFbackground, yFRFbackground, zbg = findBestBackground(outFpath, date)\n",
    "    \n",
    "    xxFRFbackground, yyFRFbackground = np.meshgrid(xFRFbackground, yFRFbackground)\n",
    "    xxFRFbackground = np.ma.masked_where(yyFRFbackground > 4500, xxFRFbackground)\n",
    "    yyFRFbackground = np.ma.masked_where(yyFRFbackground > 4500, yyFRFbackground)\n",
    "    zb = np.ma.masked_where(yyFRFbackground > 4500, zbg)\n",
    "    xCoarse, yCoarse, zCoarse, xn, yn = coarseBackground(x=xFRFbackground, y=yFRFbackground, z=zbg, cdx=cdx, cdy=cdy)\n",
    "\n",
    "    # what file string should i label plots with?\n",
    "    fileString = \"{}_{}_{}_{}\".format(date.strftime('%Y%m%d'), Lx, Ly, nmseThresh)\n",
    "    \n",
    "    # isolate data which data to include from larger data call above\n",
    "    if bathyAll is not None:\n",
    "        idxBathy = np.argwhere((bathyAll['time'] < date + dt) & (bathyAll['time'] > date)).squeeze()\n",
    "        # need to remove xFRF, yFRF from default exempt list because x,y points are co-located to elvations\n",
    "        bathy = sb.reduceDict(bathyAll, idxBathy, exemptList=['time', 'name', 'wavefreqbin'])\n",
    "    if duneAll is not None:\n",
    "        idxDune = np.argwhere((duneAll['time'] < date + dt) & (duneAll['time'] > date)).squeeze()\n",
    "        dune = sb.reduceDict(duneAll, idxDune)\n",
    "    else:\n",
    "        dune = None\n",
    "    if pierAll is not None:\n",
    "        idxPier = np.argwhere((pierAll['time'] < date + dt) & (pierAll['time'] > date)).squeeze()\n",
    "        pier = sb.reduceDict(pierAll, idxPier)\n",
    "    else:\n",
    "        pier = None\n",
    "        \n",
    "    if clarisAll is not None:\n",
    "        idxClaris = np.argwhere((clarisAll['time'] < date + dt) & (clarisAll['time'] > date)).squeeze()\n",
    "        claris = sb.reduceDict(clarisAll, idxClaris)\n",
    "    else:\n",
    "        claris=None\n",
    "    if bathyAll is None and dune is None and claris is None and pier is None:\n",
    "        continue\n",
    "    \n",
    "    # concatenate available data to bin and grid\n",
    "    \n",
    "    xs,ys,zs,types = buildCollectiveXYZ(bathy, dune, pier, claris)\n",
    "    if len(types) == 0:\n",
    "        print('    No available Data to integrate')\n",
    "        continue\n",
    "    print(\"incorporating {} data\".format(types))\n",
    "    # bin the data (xs, ys, zs) into xn and yn boundaries\n",
    "    binned = binMorph(xn, yn, xs, ys, zs)\n",
    "    \n",
    "    bc = binned['binCounts']\n",
    "    cellIDsAboveBinThresh = np.nonzero(bc > countBinThresh)\n",
    "    if np.size(cellIDsAboveBinThresh) == 0:\n",
    "        continue\n",
    "    bcvals = bc[cellIDsAboveBinThresh]\n",
    "    zbin = binned['zBinVar']\n",
    "    # check standard error to see if noise value you chose is reasonable\n",
    "    stdErr = np.sqrt(zbin[cellIDsAboveBinThresh] / bc[cellIDsAboveBinThresh])\n",
    "    zFluc = binned['zBinMedian'][cellIDsAboveBinThresh] - zCoarse[cellIDsAboveBinThresh]\n",
    "    \n",
    "    ofname = os.path.join(putFilesHere, fileString +'_preprocess.png')\n",
    "    objMapPlots.binnedDataPlot(ofname, binned, xCoarse, yCoarse, cellIDsAboveBinThresh, stdErr, zFluc)\n",
    "\n",
    "    # extract relevant domain from background Values for mapping from coarser grid scale add some for the smoothing\n",
    "    #   eg Lx/y * 3\n",
    "    xmin = np.min(xCoarse[cellIDsAboveBinThresh]) - Lx * 3                                       # min cross-shore\n",
    "    xmax = np.max(xCoarse[cellIDsAboveBinThresh]) + Lx * 3                                       # max cross-shore\n",
    "    ymin = np.min(yCoarse[cellIDsAboveBinThresh]) - Ly * 3                                       # min alongshore\n",
    "    ymax = np.max(yCoarse[cellIDsAboveBinThresh]) + Ly * 3                                       # max alongshore\n",
    "    # find appropriate indices that are in the subsection of the domain\n",
    "    idInt = np.where((xCoarse > xmin) & (xCoarse < xmax) & (yCoarse > ymin) & (yCoarse < ymax))\n",
    "    \n",
    "    # checking the index created\n",
    "    ofname = os.path.join(putFilesHere, fileString + '_indexCheck.png')\n",
    "    objMapPlots.scatterDEM(x=xCoarse[idInt], y=yCoarse[idInt], z=zCoarse[idInt], title='Background Grid Values '\n",
    "                           'defined by subset', label='elevation [m]', ofname=ofname)\n",
    "    \n",
    "    dgcov, dcovE, A, Aprime, mapFluc, nmseEst, dcovA, dcovA2, sigVar = map_interp(x=xCoarse[cellIDsAboveBinThresh],\n",
    "                                                                                  y=yCoarse[cellIDsAboveBinThresh],\n",
    "                                                                                  zFluc=zFluc,\n",
    "                                                                                  noise=noise, Lx=Lx, Ly=Ly,\n",
    "                                                                                  xInt=xCoarse[idInt],\n",
    "                                                                                  yInt=yCoarse[idInt])\n",
    "\n",
    "    # initialize arrays\n",
    "    allzeros = np.zeros_like(xCoarse)\n",
    "    nmseest = np.ones_like(xCoarse)\n",
    "    mapfluc = np.zeros_like(xCoarse)\n",
    "    \n",
    "    nmseest[idInt] = nmseEst.T\n",
    "    mapfluc[idInt] = mapFluc\n",
    "    goodi = np.nonzero(nmseest <= nmseThresh)\n",
    "    badi = np.nonzero(nmseest > nmseThresh)\n",
    "    mapfluc[badi] = allzeros[badi]\n",
    "    \n",
    "    mapz = mapfluc + zCoarse\n",
    "    \n",
    "    # look at error estimates\n",
    "    if len(goodi[0]) == 0:  # there's no good points\n",
    "        continue\n",
    "    ofname=os.path.join(putFilesHere, fileString +'_postprocessing.png')\n",
    "    objMapPlots.postProcessedGridPlot(ofname, xCoarse, yCoarse, nmseest, mapfluc, mapz, goodi)\n",
    "    \n",
    "    # now lets interpolate these accepted values to the 5 x 5 m grid\n",
    "    xgood = xCoarse.flatten()\n",
    "    ygood = yCoarse.flatten()\n",
    "    points = np.vstack([xgood, ygood])\n",
    "    points = points.T\n",
    "    zgood = mapz.flatten()\n",
    "    # interpolate coarse grid to the background values\n",
    "    fi = interpolate.griddata(points=points, values=zgood, xi=(xxFRFbackground, yyFRFbackground), method='linear')\n",
    "    \n",
    "    #zcfi = fi(xc, yc)\n",
    "    # objMapPlots.scatterDEM(xxFRFbackground, yyFRFbackground, fi, label='elevation[m]', cmap='ocean_r',\n",
    "    #                        title='Merging products where Error acceptable')\n",
    "    \n",
    "    print('add capability to see how many points have been included in new grid')\n",
    "    #################\n",
    "    # do comparison of residuals at each survey point subtracted from grid as scatter plotted over grid and 1-1 plot\n",
    "    # do cross-shore profile and alongshore profile at a few points\n",
    "    outFname = os.path.join(putFilesHere, \"QAQCplot_\"+ fileString +\".png\")\n",
    "    diff = fi - zbg\n",
    "    pierRMSE, duneRMSE, bathyRMSE = objMapPlots.QAQCplot(outFname, xxFRFbackground, yyFRFbackground, fi,  bathy,\n",
    "                                                dune, pier, diff=diff, xbounds=[0, 1200], ybounds=[-200, 1500])\n",
    "    ########## preprocess for netCDF output as needed #############\n",
    "    fi = np.expand_dims(fi.squeeze(), 0)\n",
    "    updateTime = (np.ones_like(fi) * -999)\n",
    "    mask = diff != 0\n",
    "    updateTime[0][mask] = date.timestamp()\n",
    "    \n",
    "    out = {'xFRF':       xFRFbackground,\n",
    "           'yFRF':       yFRFbackground,\n",
    "           'elevation':  fi,\n",
    "           'time':       np.expand_dims(date.timestamp(), 0),\n",
    "           'latitude':   np.ones_like(fi) * -999,\n",
    "           'longitude':  np.ones_like(fi) * -999,\n",
    "           'y_smooth':   np.ones_like(np.expand_dims(date.timestamp(), 0)) * -999,\n",
    "           'updateTime': updateTime,\n",
    "           'RMSEvals': np.expand_dims([pierRMSE, duneRMSE, bathyRMSE],0),\n",
    "           'RMSEval': [1,2,3]}\n",
    "    \n",
    "    ofname = os.path.join(outFpath, 'CMTB_integratedBathy_fused_{}.nc'.format(date.strftime(\"%Y%m%d\")))\n",
    "    varYml = \"/home/spike/repos/makebathyinterp/yamls/IntegratedBathy_grid_var.yml\"\n",
    "    globalYml = \"/home/spike/repos/makebathyinterp/yamls/BATHY/FRFti_global.yml\"\n",
    "    p2nc.makenc_generic(ofname, globalYml, varYml, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cdb5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
